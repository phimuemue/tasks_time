\chapter{Three Processors}
\label{chap:p3}

\input{p3/hlf_not_optimal}

\section{Disproving two intuitive approaches}
\label{sec:p3-disproving-long-p3-and-short-p1-time}

We first define some variants of run time. We consider the overall run time and the time where -- within a schedule of an intree -- exactly $p$ processors are working (i.e. where exactly $p$ tasks are scheduled).

\begin{definition}[Run time and its variants]
  We denote by $T$ the random variable describing the expected run time for a schedule associated with an intree. 

  Moreover, we call the time where exactly $p$ taks are scheduled by $T_p$.
\end{definition}

Note that we have that -- for three processors -- $T=T_1 + T_2 + T_3$. Since the expectation is a linear operator, we can conclude that $\E{T}=\E{T_1}+\E{T_2}+\E{T_3}$. It is our goal to minimize $\E{T}$. We will now inspect some properties concerning $T_1$, $T_2$ and $T_3$ concerning the three processor case.

If we want to construct an optimal P3 schedule, we might be tempted to think that (at least) one of the two following criteria could be fulfilled:

\begin{description}
\item[P3L] For the optimal schedule, $\E{T_3}$ should be maximal (over all schedules).
\item[P1S] For the optimal schedule, $\E{T_1}$ should be minimal (over all schedules).
\end{description}

Surprisingly, \emph{both} of them are wrong (at least if considered separately).

Figure \ref{fig:p3-p3l-suboptimal-example} shows an example, where the optimal schedule keeps three processors busy for expected 0.77777 time steps, while a suboptimal schedule keeps three processors busy for a longer expected time, namely about 0.851852 time steps.

From this we can conclude that it may be advantageous in some cases to accept a shorter time with three busy processors, thereby possibly also decreasing the time where only one processor is busy.

\begin{figure}[ht]
  \centering
  \input{p3/p3l_suboptimal}
  \caption{An intree whose optimal schedule is expected to keep three processors busy for roughly 0.77777 time steps, while a suboptimal schedule is expected to keep three processors busy for roughly 0.851852 time steps.\todo{See figure \ref{fig:p3-p1s-suboptimal-example}!}}
  \label{fig:p3-p3l-suboptimal-example}
\end{figure}

Figure \ref{fig:p3-p1s-suboptimal-example} shows an intree with the property that the optimal schedule has an expected timespan of roughly 2.59259, within which only one processor is busy. On the other hand, a suboptimal schedule has a timespan of roughly 2.55555 within which only one processor is busy.

This shows that it can be useful to accept a longer time with only one processor busy, probably acchieving a longer time span where three processors are busy.

\begin{figure}[ht]
  \centering
  \input{p3/p1s_suboptimal}
  \caption{An intree where the expected time with only one processor being busy is longer within the optimal schedule ($\approx 2.59259$) than within a suboptimal schedule ($\approx 2.555555$).\todo{Write expected times which only one busy processor in subfigures.} \todo{Convert to fractions.}\todo{Which one is optimal? Subfigures!}}
  \label{fig:p3-p1s-suboptimal-example}
\end{figure}

It can also be shown that even combining the two arguments -- in the sense that P3L \emph{or} P1S should be fulfilled for the optimal schedule -- is not correct. This can be observed by examining the intree $(0, 0, 1, 1, 2, 3, 3, 3)$. Figure \ref{fig:p3l-p1s-combo-suboptimal} shows this example.

\begin{figure}[ht]
  \centering
  \input{p3/p3l_p1s_suboptimal.tex}
  \caption{A combination of P3L and P1S is not an optimality criterion for an optimal schedule.\todo{Subfigures.}}
  \label{fig:p3l-p1s-combo-suboptimal}
\end{figure}

That is, we have seen examples that the following holds.

\begin{corollary}
  Let $T^s$ denote the overall run time of a schedule $s$ and $T_1^s$, $T_2^s$ and $T_3^s$ be the times where exactly three, two and one tasks are scheduled within this schedule, respectively.

  Let $I$ be an intree and $S$ be the set of all schedules. Let $s^*$ be the optimal schedule, which has associated the optimal run time $T^*$, with $T_1^*, T_2^*, T_3^*$ being its parts.
  \begin{itemize}
  \item It may be the case that $\exists s\in S.\  T_3^s \geq T_3^*$.
  \item It may be the case that $\exists s\in S.\  T_1^s \leq T_1^*$.
  \end{itemize}
\end{corollary}

That is, it is not necessarily the case that $T_3$ is maximal for the optimal schedule, nor is it necessarily the case that $T_1$ is minimal for the optimal schedule.

However, after some investigation, we are tempted to conjecture the following.

\begin{conjecture}
  Let $I$, $T^s, T_1^s, T_2^s, T_3^s$ and $S$ be as defined above. Let $s^*$ be the optimal schedule for $I$ associated with the respective times $T_1^*, T_2^*, T_3^*$. Then, there is no $s\in S$ such that $T^s > T^* \wedge T_1^s \leq T_1^* \wedge T_3^s \geq T_3^*$.
\end{conjecture}

\section{Size of the snapshot DAG}
\label{sec:p3-size-of-snapshot-dag-first-attempts}

Similar to the reasoning in section \ref{sec:p2-snapshot-dag}, we can research the size of a snapshot DAG for the P3 case. 
We conducted an experiment and examined the size for snapshot DAGs of intrees containing up to 17 tasks. 
We thereby examined as well the optimal DAG as the DAG arising from a scheduling strategy that can pick \emph{any} leaf.
Since the size of the snapshot DAG for an intree with $n$ tasks is at most $n^3$ times as large as the number of subtrees of the original intree, we also computed the number of subtrees for each of these intrees.
The results are summed up in table \ref{tab:num-subtrees-size-of-dags}\todo{Complete!}.

\begin{table}[ht]
  \centering
  \begin{tabular}[ht]{ccccc}
    \multirow{2}{*}{Degree} & \multicolumn{2}{c}{Subtrees} & \multicolumn{2}{c}{Snapshot DAG} \\
    & Max & Avg & Max & Avg \\
    \hline
    3 & 3 & 3.00 & 3 & 3.00  \\
    4 & 5 & 4.25 & 5 & 4.25  \\
    5 & 7 & 5.89 & 7 & 5.89  \\
    6 & 11 & 8.10 & 11 & 8.05  \\
    7 & 16 & 11.04 & 16 & 10.81  \\
    8 & 24 &  15.10 & 22 & 14.37  \\
    9 & 34 &  20.57 & 31 & 18.76  \\
    10 & 54 &  28.08 & 41 & 24.16  \\
    11 & 79 &  38.33 & 55 & 30.67  \\
    12 & 119 & 52.41 & 71 & 38.41  \\
    13 & 169 &  71.69 & 89 & 47.49  \\
    14 & 269 &  98.19 & 113 & 58.05  \\
    15 & 357 &  125.70 & 142 & 67.83  \\
    16 & 594 &  171.29 & 184 & 80.55  \\
    17 & 807 &  225.45 & 235 & 94.35  \\
  \end{tabular}
  \caption{Number of subtrees, size of the optimized snapshot DAG}
  \label{tab:num-subtrees-size-of-dags}
\end{table}

As we can see in table \ref{tab:num-subtrees-size-of-dags}, the number of subtrees is (at least for $n\geq  9$ significantly larger than the number of snapshots in the snapshot DAG describing an optimal schedule.

Another interesting fact is that there is no ``strict correlation'' between the number of subtrees and the number of snapshots in the optimal snapshot DAG. That is, there are certain DAGs that have more non-isomorphic subtrees than another DAG, yet -- on the other hand -- more snapshots in the optimal snapshot DAG. Moreover, intrees containing $n$ tasks and having the maximal number of subtrees are (at least for $8\leq n \leq 17$) are not the ones having the largest optimal snapshot DAG.

%%% Local Variables:
%%% TeX-master: "../thesis.tex"
%%% End: 